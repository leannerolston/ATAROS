# Changed stance column to factor:
fine_annotated_binary_features$stance <- as.factor(fine_annotated_binary_features$stance)

# Collapsed stance 3 into stance 2:
0    1    2 
3718 6311 3340 

Algorithm:  Train a Support Vector Machine.  Take the ``combinatorial 
support vectors'' and use them to train a second SVM.  Then take THOSE
support vectors and make ranking calculations. 

Should try this as a binary test;

Stance vs none (0 vs 1/2)
Stance strong vs stance weak (1 vs 2)

#Stance vs none:
binary_stance_vs_none <- fine_annotated_binary_features
binary_stance_vs_none[binary_stance_vs_none$stance == "2", ] <- 1
binary_stance_vs_none$stance <- factor(binary_stance_vs_none$stance)
table(binary_stance_vs_none$stance)
   0    1 
   3718 9651 

#Strong vs Weak 
binary_strong_vs_weak <- fine_annotated_binary_features[fine_annotated_binary_features$stance != 0,]

Models: binary_tune_2, binary_stance_vs_none_tune_2, 
	binary_strong_vs_weak_tune_2
Saved as:
write.svm(binary_tune_2$best.model, svm.file = "/Users/rolston/Desktop/ATAROS/models/binary_tune_2.model")
write.svm(binary_stance_vs_none_tune_2$best.model, svm.file = "/Users/rolston/Desktop/ATAROS/models/binary_stance_vs_none_tune_2.model")
write.svm(binary_strong_vs_weak_tune_2$best.model, svm.file = "/Users/rolston/Desktop/ATAROS/models/binary_strong_vs_weak_tune_2.model")

#Gather the "combinatorial SVs" for the next round:
- What are our class labels?  
<tune>$best.model&index:
index: index of the support vectors in the input data 
 
#Map these indices to a support vector, grab class.  Train on this data.
binary_tune_2_SV <- fine_annotated_binary_features[binary_tune_2$best.model$index,]
binary_strong_vs_weak_tune_2_SV <- binary_strong_vs_weak[binary_strong_vs_weak_tune_2$best.model$index, ]
binary_stance_vs_none_tune_2_SV <- binary_stance_vs_none[binary_stance_vs_none_tune_2$best.model$index, ]


#Now we need to train a linear model on these.
binary_CSV_tune <- tune(svm, stance ~., data = binary_tune_SV[, 3:39], kernel = "linear")

- I'm getting errors on linear models.  Practical Guide to SVMs say
some RBF are equivalent to linear models, so I am trying RBF.  They're
getting bad results (~50% accuracy).  I am going to try to re-tune using
a wider range of gamma and cost values.  There's no held out test data
here, so overfitting is not really an issue. So high C is ok.

> binary_tune_2_SV_tune_SupportVectors

Parameter tuning of ‘svm’:

- sampling method: 10-fold cross validation 

- best parameters:
        gamma cost
		 0.0009765625  128

		 - best performance: 0.4865711 

> binary_stance_vs_none_tune_2_SupportVectors

Parameter tuning of ‘svm’:

- sampling method: 10-fold cross validation 

- best parameters:
        gamma cost
		 0.0009765625   32

		 - best performance: 0.3884312 


> binary_strong_vs_weak_tune_2_SupportVectors

Parameter tuning of ‘svm’:

- sampling method: 10-fold cross validation 

- best parameters:
        gamma cost
		 0.0009765625    1

		 - best performance: 0.4869979 

write.svm(binary_tune_2_SV_tune_SupportVectors$best.model, svm.file="/Users/rolston/Desktop/ATAROS/models/binary_tune_2_SV.model")

> write.svm(binary_stance_vs_none_tune_2_SupportVectors$best.model, svm.file="/Users/rolston/Desktop/ATAROS/models/binary_stance_vs_none_tune_2_SV.model")
> write.svm(binary_strong_vs_weak_tune_2_SupportVectors$best.model, svm.file="/Users/rolston/Desktop/ATAROS/models/binary_strong_vs_weak_tune_2_SV.model")

I have a list, but I'm wondering if handling the dialect act stuff 
separately might be better:
binary_tune_3 <- tune(svm, stance ~., data=fine_annotated_binary_features[,c(3, 16:39)], ranges = list(gamma = 2^(-10), cost = 2^(-10:15)))

